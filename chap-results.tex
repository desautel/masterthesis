%!TEX root = foo-thesis.tex


\chapter{Results and Discussion}
\label{chap:results}

This chapter details the performance and quality characteristics of the implemented techniques and  examines their memory usage. For each technique, it will subsequently discuss the up- and downsides and identify alternatives.

\section{Scenes, Settings and Testing System}

The implementation is tested in the Crytek Sponza and San Miguel scene, with 260k and 7.9M triangles respectively, both provided by \citet{McGuire2011Data}.

Unless otherwise noted, the parameters used for the measurements and screenshots are:
\begin{outline}
    \1 1920x1080px output resolution
    \1 1024 VPLs
    \1 2048px² ISM texture, i.\,e.\ 64px² per ISM
    \1 Single-pixel point renderer enabled, 16 VPLs considered per point, up to 4 collected
    \1 4x4 interleaving pattern
    \1 Clustered shading: 128px² tile size, 16 depth slices
\end{outline}

\noindent
The hardware specification of the testing system is as follows:
\begin{outline}
    \1 Intel Xeon dadada
    \1 NVIDIA GeForce GTX 750 Ti, locked to xxx Mhz for reproducible results
    \1 mainboard?
    \1 other stuff?
\end{outline}

\todo{hardware specifications}

\section{RSM Generation and VPL Sampling}
\begin{outline}
\1 RSM generation is the same as G-Buffer generation, possibly with a different resolution. as said earlier, depending on the specific use case, this rendering pass can also render the shadowmap.
\1 screenshot of RSM G-buffers

\1 VPL sampling takes fractions of a millisecond and is negligible. bear in mind that in order to achieve high quality levels, a more elaborate sampling algorithms needs to be implemented, which can actually take most of the available time. See \citep{hedman2016sequential} for an advanced sampling algorithm.
\1 screenshots of debug splotches visualized

\1 our sampling pays no attention to relevance to the current frame and wastes budget on lights contributing little or nothing
\1 screenshot of VPLs on the roof

\1 our sampling has the additional downside of poor temporal stability when the scene light moves. this is due to each VPL staying at the exact same position in the light's viewport, so it ``follows'' the light's movements in a certain way, jumping over depth discontinuities along the way.

\1 frame-to-frame coherency here? two screenshots with diff.
\end{outline}


\section{ISM Rendering}

\subsection{Point Rendering with Splatting}

\Cref{fig:???} shows the Crytek Sponza scene rendered using ISMs created by the splat renderer (a) and the single-pixel renderer (b). A section of the ISM texture is shown for each renderer in the lower row.


\subsubsection{Quality}

What becomes apparent is that renderer x does z while renderer y preserves w. Also note the darkening by renderer x, y does not do that.

Screenshots when enlarging the points / making them smaller. Discuss.

Screenshots when doing more points. either by tessellation or by collecting more. Discuss.

\todo[color=yellow]{count point for splat renderer and output them somehow.}

Compare to max quality

\todo[color=yellow]{implement max quality. every point into every ISM. likely render everything once for each ISM. a checkbox: when checked, compute high-quality once and don't change. back to normal when unchecked.}

for single-pixel-renderer: maybe show one full-size shadowmap to show this *can* work


\subsubsection{Performance}

In the screenshots above, x needs z ms, while y needs w ms. Since the technique implements no adaptivity, these numbers are independent from the viewport and (largely) from the VPL placement.

Numbers when the VPLs are somewhere else. but, should not happen with more intelligent VPL sampling.

Numbers when enlarging the points / making them smaller. Discuss. Note how the single-pixel renderer is (hopefully) not affected by point size.

Numbers when doing more points. either by tessellation or by collecting more. Discuss.


\subsubsection{Detailed Performance Measurements for the Single-Pixel Point Renderer}

Split time into point collection, point rendering, postprocessing

Impact of packing

show this is bandwidth bound. calculation how much memory is read and written, vs bandwidth of GTX 980.


\subsubsection{Memory Usage}

Point splat renderer uses just the ISM.

Single-pixel renderer uses point buffer, mipmaps, additional render targets.


\subsubsection{Problems with High Geometric Density}

As a more demanding test case the San Miguel scene with 7.9M triangles. The most apparent problem of the presented implementation is the lack of adaptivity to the current viewport and VPL positions in addition to the lack of LOD methods. As a result, all 7.9M triangles are used every frame to render the ISMs, with corresponding performance results.

Screenshots with the San Miguel scene

Quality also suffers. Not tuned to such small triangles.

Numbers

\subsection{Comparison and Discussion}
\begin{outline}
    \1 comparison of pull-push vs splatting
    \1 ISMs have several deficits, starting with reducing the scene's geometry to points. This is already a simplification that trades speed for accuracy.
    \1 Second, because we use a sparse point set for each ISM, each point must be enlarged to accomodate for the missing points. For instance, if an area is represented by a thousand points and we now use one tenth of all points for an ISM, each remaining point's area must be enlarged by a factor of ten to result in an equally large area in the rendered output. Of course, this approach leads to deformed geometry since points at the edges of the area get enlarged as well, growing over the borders of the original geometry.
    \1 Third, there are also numerical issues. For instance, both the splatting and postprocessing approaches ignore the distortion caused by the projection, and thus might render even simple surfaces incorrectly. This contributes to the necessity of using a relatively large shadow bias.
    \1 A massive improvement would be to differentiate between large-scale scene geometry that is important for global illumination, and smaller geometry of lesser importance. While the latter can possibly be ignored altogether with only minor losses in quality, the shape of large-scale geometry is all the more important to preserve (relatively) precisely.
    \1 The San Miguel scene is a good example for this: While the small detail work like dishes and small plants make up most of the geometry and thus most of the rendering time, they contribute only very little to global illumination. This is where our implementation suffers most from the lack of level-of-detail methods.
\end{outline}



\todo[color=blue]{ISM rendering results}


\section{Interleaved Shading with Compute Shaders}

\begin{outline}
\1 performance
\1 1x1 and 4x4, if i'm good also 2x2 and 8x8...
\1 quality
    \2 screenshots with and without, with details on e.g. foliage, diffimage? and shaded result
\1 memory usage
    \2 one additional buffer
\1 discussion

\end{outline}

\todo[color=blue]{interleaved shading results}


\section{Clustered Deferred Shading}


\begin{outline}
\1 parameters: cluster size
\1 performance: time used by additional steps vs saved in GI step
\1 quality: exactly the same
\1 memory usage for the one intermediate result and the light lists buffer
\1 performance of tiled shading. comparable, no memory usage, easier to implement, but less flexible.
\1 discussion
\end{outline}


\todo[color=blue]{clustered deferred shading results}


- one 4k test?
