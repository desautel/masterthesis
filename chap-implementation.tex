%!TEX root = foo-thesis.tex


\chapter{Implementation}

\section{Used Libraries and the Framework gloperate}

\todo[color=green]{software architecture?}

- some architecture diagram of dependencies?
- gloperate as framework
    - uses qt
- libzeug provides GUI elements
- globjects as an object-oriented abstraction over OpenGL
- glbinding provides OpenGL bindings, directly called sometimes
- GLM provides math and easier interaction with the OpenGL API
- no further relevance for this thesis:
    - assimp for model loading
    - glkernel provides kernels for our SSAO implementation
    - cpplocate ???

\section{Rendering Pipeline Overview}
- would be much the same as the concept pipeline...
- show what's compute shader and what not?
- it's basically lighting plus
    - g-buffer generation
    - shadowmap which is part of the RSM,
    - SSAO
    - deferredshading
    - srgb and HDR.
    - all of this is not
- model loading?
- kernel generation?


\section{RSM Generation and VPL Sampling}
\label{sec:impl:rsmAndVplSampling}
- use the exact same code for RSM generation as for G-Buffer generation
- re-use RSM as shadowmap
    - usually, one might want to decouple this since they likely need different resolutions/cascading schemes etc. One could also render the RSM with a less detailed version of the scene. Since we had no culling and LOD implemented, we were bottlenecked on geometry complexity and chose to do this in one pass.
    - we use variance shadowmapping. so we add the variance buffer if we're rendering an RSM, and disable another buffer (non-face normals).

- with a compute shader, we sample the RSM in a regular pattern and write VPLs into a buffer
- VPLs are position, normal, color
- we prepare a second buffer with a single vec4 with position in the first three values and normal packed into the last value.
- we do that since the ISM rendering (Section~\ref{sec:impl:ismRendering}) and light list calculation (Section~\ref{sec:impl:clusteredShading}) do not need color and especially ISM rendering reads several VPLs per point, using a lot of bandwidth.
- Because of the regular sampling, the noise produced during interleaved shading (Section~\ref{sec:impl:interleavedShading} or only results? there was a paper that sorts VPLs to avoid the noise...) is more structured. To help with that, we permutate the VPL order with a random permutation computed on CPU

\section{ISM Rendering}
\label{sec:impl:ismRendering}
- Our ISM rendering normally draws all the geometry in the scene.
- In the tessellation control shader, the tesselation levels are determined depending on the triangle size.
- The tessellation evaluation shader does nothing besides correctly interpolating the triangle's vertices.
- The geometry shader, which now recieves a small (tesselated) triangle, computes the point data
- i.e. position: center of triangle, radius: distance of center to farthest triangle vertex, normal: the face normal taken from the original, non-tessellated triangle.

- the geometry shader then calculates a random VPL ID. We used the point's position to seed the random number generator. This makes the ISMs temporally unstable when the geometry moves, but we couldn't find a stable seed.

\todo[color=blue]{implement randomness based on barycentric coordinates}

- two approaches:

- either the geometry shader itself reads the VPL with the index it determined, projects the point according to the VPL's data, sets gl\_PointSize to the projected size, and emits a vertex.
- also, output mode is points.

- \citet{Marroquim:2007:reconstruction} actually works with single-pixel ``splats''. since in this case we're not depending on the hardware rasterizer for good performance, this inspired the following approach:

- instead of splatting, the geometry shader puts points into buffer
- one buffer per VPL for stability
- buffers index marks the first VPL to try
- then, per point in each buffer, starting with the respective VPL, we test a fixed number of VPLs (e.\,g. 16) and collect up to 4 that pass culling tests.
- specifically, backface culling and points that are located behind the VPL, i.\,e. not in the hemisphere pointing along the VPL's normal.
- we then render the point as a single pixel into the 4 collected VPLs.

\todo{part of this into concept}


- hole mitigation
- when splatting, the quality difference improvement achieved with an additional pull-push algorithm compared to slightly larger splats seemed not worth the performance impact, therefore we chose to simply enlarge all splats a bit.
- when using compute shaders, we need pull-push by design.

\todo{explain pullpush implementation}

\section{Interleaved Shading with Compute Shaders}
\label{sec:impl:interleavedShading}
- often, de-interleaving is implemented by splitting the G-buffer into several smaller G-buffers, each containing all pixels with the same sample set \cite{segovia2006non}. Each G-buffer is processed with its respective sample set, and then the buffers are re-interleaved into a large G-Buffer again.


- we do this in a single pass. Downside: scattered read. but: the shading pass is bottlenecked on lookups in the VPL buffer and the respective shadowmaps, as well as ALU operations. A one-time scattered read does not hurt.
- in fact, any attempts to do coherent reads did not result in speedups.
- diagram of the pixels. \ref{fig:impl:pixels} explain this. we still do coherent VPL processing.

\todo[color=blue]{same set of lights per interleave pixel. right now, if adjacent pixels have different clusters, they might process the same lights.}

- Since only a subset of all samples is processed per pixel and this subset repeats every four pixels, this process results in structured noise (see Figure \ref{fig:???} or this figure in concept?)
- therefore, geometry-aware blur similar to \citet{laine2007incremental}. doesn't smooth over edges. See code snippet \ref{listing:???}. every pixel has all the information now ideally.

- VPL shuffling helps a great deal! See Figure \ref{fig:impl:shuffling}

\section{Clustered Deferred Shading}
\label{sec:impl:clusteredShading}

- we use 128 pixels as screen-space tile width and 16 depth slices. We also use an optimization proposed by \citet{???practical} and use a larger near cluster for better depth slice utilization.
- we do not use explicit bounds, since we expect only small gains by that. although it might result in larger gains, we have have not implemented using normals for clustering yet.
- \citet{???practical} do culling on the CPU. they have small radii and can therefore quickly determine the clusters that are reached by a certain light.
- we have infinite light radii and therefore lots of clusters per light. therefore, we can expect to cull maybe half the lights and not the majority.
- therefore, we decided to iterate over all lights per used cluster, as opposed to iterate over reached clusters per light.
- the more uniform control flow of this approach as also better suited to GPUs.

- two passes:

- as explained, we want to iterate over all lights per cluster. to do this efficiently, we need a list of used clusters.

- first pass produces this list., one work group per screen-space tile. has one boolean for each depth slice indicating whether it's used. read all the pixels, determine depth slice and set its boolean to true.
- then it adds the number of used depth slices to one global atomic counter. the glsl function to do this returns the value of the counter before the addition.
this way, each workgroup ``allocates'' some space in the list of used clusters. it then writes an id for each cluster into that list.

- second pass iterates over all lights per cluster, adding all lights that potentially illuminate the cluster to a list.
- in order to do this, we determine the world positions of the eight corners of the cluster. if any of them lies inside the VPLs hemisphere, we add the light to the list.
- show some code? but it's really ugly...

- during shading, when processing a pixel, the pixel's cluster is first determined and only the lights of this cluster's light list are processed.

- we use a very basic approach to combine this with interleaved shading: of all lights in the light list, each pixels gets an equally sized fraction. while this might lead to adjacent pixels processing overlapping sets of lights if they are in different clusters, they are either in clusters near to each other in which case the light lists are probably quite similar, or they are in clusters seperated from each other so the geometry-aware blur wouldn't consider them anyway.
